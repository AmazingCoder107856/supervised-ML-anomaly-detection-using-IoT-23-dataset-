{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f65d1e-60f8-4bcd-8006-543fe0fe3c4b",
   "metadata": {},
   "source": [
    "# Supervised ML for anomaly detection in IOT to enahnce network security\n",
    "## Part 3 - DATA TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd01914-d04c-4185-83a7-31aa99c2ad4e",
   "metadata": {},
   "source": [
    "The IoT-23 dataset is a collection of network traffic from Internet of Things (IoT) devices. It includes 20 malware captures executed in IoT devices, and 3 hotspot captures for benign IoT devices traffic12. The 3 hotspot captures are not being included in the data cleaning because this feature was not considered relevant for the specific analysis being performed.\n",
    "\n",
    "In this notebook, we load the raw dataset file and implement initial cleaning to prepare it for the next processing phase.\n",
    "\n",
    "> **INPUT:** downloaded the raw dataset file from its original source. <br>\n",
    "> **OUTPUT:** a cleaned version of the dataset stored to an intermediate csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c3517c-b44a-4a54-989b-b75d8f9b90ad",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1c9c9c-80db-4f66-b424-cb4fd59d4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import precision_score, confusion_matrix, recall_score, accuracy_score, f1_score\n",
    "from statistics import mean\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e5aa31-2d06-4a21-8676-b85db0cf0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63586871-0d8a-44de-832f-cc12339425b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "data_df = pd.read_csv('../data/processed/iot23_combined_processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1e5d43f-2628-4ad1-9f5c-3b3948a58ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1444674, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset shape\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56cefc-66b8-4480-8b00-0022808bba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset head\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a166f352-5828-4668-a157-103ede434f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into independent and dependent variables\n",
    "data_X = data_df.drop(\"label\", axis=1)\n",
    "data_y = data_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863fd6c2-9d6b-4fe0-82ee-5fa0f3ecc771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classification models\n",
    "classifiers = [\n",
    "    # Since we have unbalanced labels, we use the Complement version of Naive Bayes which is particularly suited for imbalanced data sets.\n",
    "    (\"Naive Bayes\", ComplementNB()),\n",
    "    \n",
    "    # We use the Decision Tree with its default parameters, including the \"Gini Impurity\" to measure the quality of splits and ccp_alpha=0 (no pruning is performed). \n",
    "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "    \n",
    "    # Logistic Regression model to help discovering linearity separation in the data set.\n",
    "    (\"Logistic Regression\", LogisticRegression()),\n",
    "    \n",
    "    # The efficient Random Forest model with a default base estimators of 100.\n",
    "    (\"Random Forest\", RandomForestClassifier()),\n",
    "    \n",
    "    # The classifier version of Support Vector Machine model.\n",
    "    (\"Support Vector Classifier\", SVC()),\n",
    "    \n",
    "    # The distance-based KNN classifier with a default n_neighbors=5.\n",
    "    (\"K-Nearest Neighbors\", KNeighborsClassifier()),\n",
    "  \n",
    "    # The most powerful ensemble model of XGBoost with some initially tuned hyperparameters.\n",
    "    (\"XGBoost\", xgb.XGBClassifier(objective = \"binary:logistic\", alpha = 10)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0a427-e5db-4209-90df-558f3f73897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the cross-validator with 5 splits and sample shuffling activated\n",
    "skf_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9861b-66b9-4dac-b537-509386eba60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Training Started!\")\n",
    "# Initialize the results summary\n",
    "classification_results = pd.DataFrame(index=[c[0] for c in classifiers], columns=[\"Accuracy\", \"TN\", \"FP\", \"FN\", \"TP\", \"Recall\", \"Precision\", \"F1\"])\n",
    "\n",
    "# Iterate over the estimators\n",
    "for est_name, est_object in classifiers:\n",
    "    \n",
    "    print(f\"### [{est_name}]: Processing ...\")\n",
    "    \n",
    "    # Initialize the results for each classifier\n",
    "    accuracy_scores = []\n",
    "    confusion_matrices = []\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    # Initialize best model object to be saved\n",
    "    models_path = \"..\\\\models\"\n",
    "    best_model = None\n",
    "    best_f1 = -1\n",
    "    \n",
    "    # Iterate over the obtained folds\n",
    "    for train_index, test_index in skf_cv.split(data_X, data_y):\n",
    "\n",
    "        # Get train and test samples from the cross-validation model\n",
    "        X_train, X_test = data_X.iloc[train_index], data_X.iloc[test_index]\n",
    "        y_train, y_test = data_y.iloc[train_index], data_y.iloc[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        est_object.fit(X_train.values, y_train.values)\n",
    "        \n",
    "        # Predict the test samples\n",
    "        y_pred = est_object.predict(X_test.values)\n",
    "        \n",
    "        # Calculate and register accuracy metrics\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        confusion_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        est_f1_score = f1_score(y_test, y_pred)\n",
    "        f1_scores.append(est_f1_score)\n",
    "        \n",
    "        # Compare with best performing model\n",
    "        if best_f1 < est_f1_score:\n",
    "            best_model = est_object\n",
    "            best_f1 = est_f1_score\n",
    "    \n",
    "    # Summarize the results for all folds for each classifier\n",
    "    tn, fp, fn, tp = sum(confusion_matrices).ravel()\n",
    "    classification_results.loc[est_name] = [mean(accuracy_scores),tn,fp,fn,tp,mean(recall_scores),mean(precision_scores),mean(f1_scores)]\n",
    "    \n",
    "    # Save the best performing model\n",
    "    if best_model:\n",
    "        model_name = est_name.replace(' ', '_').replace('-', '_').lower()\n",
    "        model_file = model_name + \".pkl\"\n",
    "        dump(best_model, models_path + \"\\\\\" + model_file)\n",
    "    \n",
    "print(\"Model Training Finished!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c00ff-f575-4480-ab85-8050af8defb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the results\n",
    "classification_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
